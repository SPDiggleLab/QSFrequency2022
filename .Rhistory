load('OBJECTS/list_of_strain_distMats_by_gene.R')
load('OBJECTS/PCA_VIZ.R')
df.truncations$similarity_mean = NA
df.truncations$similarity_sd = NA
for(gene in 'lasR'){#names(ls.refDist_by_gene)){
# Get Reference
ref_aminos = read.table(paste('INPUT/ref_genes/', gene, '_PAO1_protein.txt', sep='', collapse='')
, stringsAsFactors = F)$V1
ref_aminos = AAString(ref_aminos) # read in as biocstring object
# Calculate self-distance score
self_align = pairwiseAlignment(ref_aminos
, ref_aminos
, substitutionMatrix = "BLOSUM80"
, gapOpening=11
, gapExtension=1)@score
# normalize to self
v.dist = ls.refDist_by_gene[[gene]] / self_align
# get simple stats
mean_dist = mean(v.dist)
sd_dist = sd(v.dist)
df.truncations[gene, 'similarity_mean'] = mean_dist
df.truncations[gene, 'similarity_sd'] = sd_dist
}
# For Fig 2a
df.lasR_meta = ls.complete_gene_MetaSeq[['lasR']][,c('GENE', 'HOST', 'SOURCE', 'ENV', 'SEQUENCE')]
lasR_ref = read.table(paste('INPUT/ref_genes/lasR_PAO1_protein.txt', sep='', collapse='')
, stringsAsFactors = F)$V1
df.lasR_meta
# Get AAs
b.truncs = sapply(df.lasR_meta$SEQUENCE, function(x){
seqDNA = toString(translate(DNAString(x), if.fuzzy.codon = c('solve', 'X'), no.init.codon = T))
return(nchar(strsplit(seqDNA, '\\*')[[1]])<239)
})
nBases_lasR = nchar(lasR_ref)*3
df.lasR_meta$TRUNCATED = b.truncs#sapply(df.lasR_meta$SEQUENCE, function(x){nchar(x) < nBases_lasR})
df.lasR_meta$SEQUENCE = NULL # remove SEQ for easier reading
sum(df.lasR_meta$TRUNCATED)
b.truncs
# Get AAs
b.truncs = sapply(df.lasR_meta$SEQUENCE, function(x){
seqDNA = toString(translate(DNAString(x), if.fuzzy.codon = c('solve', 'X'), no.init.codon = T))
return(nchar(strsplit(seqDNA, '\\*')[[1]][1])<239)
})
b.truncs
# Get AAs
b.truncs = sapply(df.lasR_meta$SEQUENCE, function(x){
seqDNA = toString(translate(DNAString(x), if.fuzzy.codon = c('solve', 'X'), no.init.codon = T))
return((nchar(strsplit(seqDNA, '\\*')[[1]])<239)[1])
})
b.truncs
test = 'asdf*asd'
gregexpr('\\*', test)
gregexpr('\\*', test)[[1]]
gregexpr('\\*', test)[[1]][1]
# Get AAs
b.truncs = sapply(df.lasR_meta$SEQUENCE, function(x){
seqDNA = toString(translate(DNAString(x), if.fuzzy.codon = c('solve', 'X'), no.init.codon = T))
return(gregexpr('\\*', seqDNA)[[1]][1] == nchar(lasR_ref))
})
b.truncs
df.lasR_meta$SEQUENCE
# For Fig 2a
df.lasR_meta = ls.complete_gene_MetaSeq[['lasR']][,c('GENE', 'HOST', 'SOURCE', 'ENV', 'SEQUENCE')]
lasR_ref = read.table(paste('INPUT/ref_genes/lasR_PAO1_protein.txt', sep='', collapse='')
, stringsAsFactors = F)$V1
# Get AAs
b.truncs = sapply(df.lasR_meta$SEQUENCE, function(x){
seqDNA = toString(translate(DNAString(x), if.fuzzy.codon = c('solve', 'X'), no.init.codon = T))
return(gregexpr('\\*', seqDNA)[[1]][1] == nchar(lasR_ref))
})
b.truncs
names(b.truncs) == NULL
b.truncs
b.truncs
unlist(b.truncs)
as.vector(b.truncs)
source('~/CYZ GITHUB/Digglets/For_Conan/visualize_data_overview.R')
fig2_full
sum(as.vector(b.truncs))
df.lasR_meta$TRUNCATED = ifelse(as.vector(b.truncs), 'TRUNC', 'FULL')#sapply(df.lasR_meta$SEQUENCE, function(x){nchar(x) < nBases_lasR})
# Add column: TRUNCATED
nBases_lasR = nchar(lasR_ref)*3
df.lasR_meta$TRUNCATED = ifelse(as.vector(b.truncs), 'TRUNC', 'FULL')#sapply(df.lasR_meta$SEQUENCE, function(x){nchar(x) < nBases_lasR})
df.lasR_meta$SEQUENCE = NULL # remove SEQ for easier reading
sum(df.lasR_meta$TRUNCATED)
# If SOURCE is NA and HOST is HUMAN, assign source to non-CF
df.lasR_meta$SOURCE[(is.na(df.lasR_meta$SOURCE) & df.lasR_meta$HOST == 'Human')] = 'non-CF'
# Animals are part of the environment
df.lasR_meta$ENV[df.lasR_meta$HOST == 'Animal'] = TRUE
# Add a GROUP column for plotting
df.lasR_meta$GROUP = ifelse(df.lasR_meta$ENV, 'ENV', df.lasR_meta$SOURCE)
df.lasR_meta$GROUP[df.lasR_meta$GROUP == 'WND'] = 'non-CF' # combine WND and non-CF
# PLOT --------------------------------------------------------------------
fig1a = ggplot(df.truncations, aes(x = gene, y = similarity_mean)) +
theme_gray(base_size = 14) +
geom_bar(stat = 'identity', color = 'black') +
geom_errorbar(size =2, aes(ymin = similarity_mean-similarity_sd
, ymax = similarity_mean+similarity_sd)
, width = .5) +
ylim(c(0, 1.2)) +
xlab('') +
ylab('Normalized Similarity Score') +
scale_fill_brewer(palette = 'Paired') +
theme(legend.position = 'none'
, axis.text.x = element_text(angle = 45, hjust=1, vjust=1))
fig1a2 = ggplot(df.truncations, aes(x = n_base, y = similarity_mean)) +
theme_gray(base_size=14) +
geom_point(size=2) +
geom_text(aes(label = ifelse(similarity_mean<0.993, gene, ''))
, hjust=-0.3, vjust=0) +
ylab('Normalized Similarity Score') +
xlim(600, 1600)
fig1b = ls.pcas[['lasR']] +
theme_gray(base_size = 14) +
geom_point(color = 'black', size = 3) +
theme(legend.position = 'none') +
ggtitle('')
fig1c = ls.pcas[['lasI']] +
theme_gray(base_size = 14)  +
geom_point(color = 'black', size = 3) +
theme(legend.position = 'none') +
ggtitle('')
fig2a = ggplot(df.lasR_meta, aes(x = GROUP, fill = TRUNCATED)) +
geom_bar(stat = 'count', color = 'black')
fig2b = ls.pcas[['lasR']]
require(cowplot)
fig1_full = plot_grid(fig1a, fig1b, fig1c
, labels = c('A', 'B', 'C')
, nrow = 1
, rel_widths = c(1, 1.5, 1.5))
fig1_full
fig2_full = plot_grid(fig2a, fig2b, labels = c('A', 'B'))
fig2_full
fig2_full
df.lasR_meta$TRUNCATED = ifelse(as.vector(b.truncs), 'FULL', 'TRUNC')#sapply(df.lasR_meta$SEQUENCE, function(x){nchar(x) < nBases_lasR})
df.lasR_meta$TRUNCATED = ifelse(as.vector(b.truncs), 'FULL', 'TRUNC')#sapply(df.lasR_meta$SEQUENCE, function(x){nchar(x) < nBases_lasR})
df.lasR_meta$SEQUENCE = NULL # remove SEQ for easier reading
sum(df.lasR_meta$TRUNCATED)
# If SOURCE is NA and HOST is HUMAN, assign source to non-CF
df.lasR_meta$SOURCE[(is.na(df.lasR_meta$SOURCE) & df.lasR_meta$HOST == 'Human')] = 'non-CF'
# Animals are part of the environment
df.lasR_meta$ENV[df.lasR_meta$HOST == 'Animal'] = TRUE
# Add a GROUP column for plotting
df.lasR_meta$GROUP = ifelse(df.lasR_meta$ENV, 'ENV', df.lasR_meta$SOURCE)
df.lasR_meta$GROUP[df.lasR_meta$GROUP == 'WND'] = 'non-CF' # combine WND and non-CF
# PLOT --------------------------------------------------------------------
fig1a = ggplot(df.truncations, aes(x = gene, y = similarity_mean)) +
theme_gray(base_size = 14) +
geom_bar(stat = 'identity', color = 'black') +
geom_errorbar(size =2, aes(ymin = similarity_mean-similarity_sd
, ymax = similarity_mean+similarity_sd)
, width = .5) +
ylim(c(0, 1.2)) +
xlab('') +
ylab('Normalized Similarity Score') +
scale_fill_brewer(palette = 'Paired') +
theme(legend.position = 'none'
, axis.text.x = element_text(angle = 45, hjust=1, vjust=1))
fig1a2 = ggplot(df.truncations, aes(x = n_base, y = similarity_mean)) +
theme_gray(base_size=14) +
geom_point(size=2) +
geom_text(aes(label = ifelse(similarity_mean<0.993, gene, ''))
, hjust=-0.3, vjust=0) +
ylab('Normalized Similarity Score') +
xlim(600, 1600)
fig1b = ls.pcas[['lasR']] +
theme_gray(base_size = 14) +
geom_point(color = 'black', size = 3) +
theme(legend.position = 'none') +
ggtitle('')
fig1c = ls.pcas[['lasI']] +
theme_gray(base_size = 14)  +
geom_point(color = 'black', size = 3) +
theme(legend.position = 'none') +
ggtitle('')
fig2a = ggplot(df.lasR_meta, aes(x = GROUP, fill = TRUNCATED)) +
geom_bar(stat = 'count', color = 'black')
fig2b = ls.pcas[['lasR']]
require(cowplot)
fig1_full = plot_grid(fig1a, fig1b, fig1c
, labels = c('A', 'B', 'C')
, nrow = 1
, rel_widths = c(1, 1.5, 1.5))
fig1_full
fig2_full = plot_grid(fig2a, fig2b, labels = c('A', 'B'))
fig2_full
table(df.lasR_meta$TRUNCATED)
fig1_full
df.truncations
# Load Data
load('OBJECTS/gene_trunc_stats.R')
df.truncations
source('~/CYZ GITHUB/Digglets/For_Conan/visualize_data_overview.R')
Add column: TRUNCATED
nBases_lasR = nchar(lasR_ref)*3
df.lasR_meta$TRUNCATED = ifelse(as.vector(b.truncs), 'FULL', 'TRUNC')#sapply(df.lasR_meta$SEQUENCE, function(x){nchar(x) < nBases_lasR})
df.lasR_meta$SEQUENCE = NULL # remove SEQ for easier reading
# If SOURCE is NA and HOST is HUMAN, assign source to non-CF
df.lasR_meta$SOURCE[(is.na(df.lasR_meta$SOURCE) & df.lasR_meta$HOST == 'Human')] = 'non-CF'
# Animals are part of the environment
df.lasR_meta$ENV[df.lasR_meta$HOST == 'Animal'] = TRUE
# Add a GROUP column for plotting
df.lasR_meta$GROUP = ifelse(df.lasR_meta$ENV, 'ENV', df.lasR_meta$SOURCE)
df.lasR_meta$GROUP[df.lasR_meta$GROUP == 'WND'] = 'non-CF' # combine WND and non-CF
# PLOT --------------------------------------------------------------------
fig1a = ggplot(df.truncations, aes(x = gene, y = similarity_mean)) +
theme_gray(base_size = 14) +
geom_bar(stat = 'identity', color = 'black') +
geom_errorbar(size =2, aes(ymin = similarity_mean-similarity_sd
, ymax = similarity_mean+similarity_sd)
, width = .5) +
ylim(c(0, 1.2)) +
xlab('') +
ylab('Normalized Similarity Score') +
scale_fill_brewer(palette = 'Paired') +
theme(legend.position = 'none'
, axis.text.x = element_text(angle = 45, hjust=1, vjust=1))
fig1a2 = ggplot(df.truncations, aes(x = n_base, y = similarity_mean)) +
theme_gray(base_size=14) +
geom_point(size=2) +
geom_text(aes(label = ifelse(similarity_mean<0.993, gene, ''))
, hjust=-0.3, vjust=0) +
ylab('Normalized Similarity Score') +
xlim(600, 1600)
fig1b = ls.pcas[['lasR']] +
theme_gray(base_size = 14) +
geom_point(color = 'black', size = 3) +
theme(legend.position = 'none') +
ggtitle('')
fig1c = ls.pcas[['lasI']] +
theme_gray(base_size = 14)  +
geom_point(color = 'black', size = 3) +
theme(legend.position = 'none') +
ggtitle('')
fig2a = ggplot(df.lasR_meta, aes(x = GROUP, fill = TRUNCATED)) +
geom_bar(stat = 'count', color = 'black')
fig2b = ls.pcas[['lasR']]
require(cowplot)
fig1_full = plot_grid(fig1a, fig1b, fig1c
, labels = c('A', 'B', 'C')
, nrow = 1
, rel_widths = c(1, 1.5, 1.5))
fig1_full
fig2_full = plot_grid(fig2a, fig2b, labels = c('A', 'B'))
fig2_full
fig1_full
fig2_full
fig2_full = plot_grid(fig2a, fig2b, labels = c('A', 'B')
, rel_widths = c(1, 3))
fig2_full
fig2_full = plot_grid(fig2a, fig2b, labels = c('A', 'B')
, rel_widths = c(1, 2))
fig2_full
source('~/CYZ GITHUB/Digglets/For_Conan/MASTER_IPCD-analysis.R')
require(readxl)
require(read_xls)
install.packages('readxl')
source('~/CYZ GITHUB/Digglets/For_Conan/MASTER_IPCD-analysis.R')
install.packages('factoextra')
source('~/CYZ GITHUB/Digglets/For_Conan/MASTER_IPCD-analysis.R')
fig2a
source('~/CYZ GITHUB/Digglets/For_Conan/visualize_data_overview.R')
install.packages('Biostrings')
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("Biostrings")
source('~/CYZ GITHUB/Digglets/For_Conan/visualize_data_overview.R')
df.lasR_meta
test = split(df.lasR_meta, df.lasR_meta$GROUP)
test
lapply(test, function(x){
sum(x$TRUNCATED == 'TRUNC')/nrow(x)
})
# ad hoc 07.12.2020: what are the % truncations
lapply(split(df.lasR_meta, df.lasR_meta$GROUP), function(x){
sum(x$TRUNCATED == 'TRUNC')/nrow(x)
})
source('~/CYZ GITHUB/Digglets/For_Conan/visualize_data_overview.R')
source('~/CYZ GITHUB/Digglets/For_Conan/visualize_data_overview.R')
fig2_full
head(df.truncations)
source('~/CYZ GITHUB/Digglets/For_Conan/plot_distance_pcas_by_gene.R')
install.packages('ape')
b.has_SOURCE
p_pca
meta[rownames(df.dist), 'SOURCE'
]
meta
table(meta$SOURCE)
source('~/CYZ GITHUB/Digglets/For_Conan/plot_distance_pcas_by_gene.R')
source('~/CYZ GITHUB/Digglets/For_Conan/visualize_data_overview.R')
fig2b
fig2_full
fig2a = ggplot(df.lasR_meta, aes(x = GROUP, fill = TRUNCATED)) +
geom_bar(stat = 'count', color = 'black') +
xlab('')
fig2b = ls.pcas[['lasR']]
require(cowplot)
fig1_full = plot_grid(fig1a, fig1b, fig1c
, labels = c('A', 'B', 'C')
, nrow = 1
, rel_widths = c(1, 1.5, 1.5))
fig1_full
fig2_full = plot_grid(fig2a, fig2b, labels = c('A', 'B')
, rel_widths = c(1, 2))
fig2_full
# ad hoc 07.12.2020: what are the % truncations
lapply(split(df.lasR_meta, df.lasR_meta$GROUP), function(x){
sum(x$TRUNCATED == 'TRUNC')/nrow(x)
})
fig2_full
source('~/CYZ GITHUB/Digglets/For_Conan/visualize_data_overview.R')
fig1_full
fig2_full
fig2b
fig2a
df.lasR_meta
fig2b
source('~/CYZ GITHUB/Digglets/For_Conan/visualize_data_overview.R')
fig2_full
seir_model_shields_reduced = function(t, X, Pars) {
# Core transmission model
#   - Subscripts are defined as follows: c=children, a=non-essential adults,
#     rc=reduced contact adults, fc=full contact adults, e=elderly
#   - For infection equations: The I compartments correspond to infectious
#     periods, not periods in which people are symptomatic
#   - Is are cases that are severe enough to be documented eventually and Ia are undocumented cases
#   - Since we are not fitting to data we do not need to model specifically when the cases are documented
#   - _pos indicates people who have tested positive for COVID-19 by antibody test
test.switch1<-sw1fxn(t)
test.switch2<-sw2fxn(t)
# (0) Setup ---------------------------------------------------------------
# Load all pars
for(i_par in 1:length(Pars)){
assign(names(Pars)[i_par], Pars[[i_par]])
}
# Update Pars
socialDistancing_other_c = 1-(0.75*c)
p_reduced_c = 1-(0.9*c)
# Load all Vars
for(i_var in 1:length(X)){
assign(names(X)[i_var], X[[i_var]])
}
# Load in Matrix Form
mat_X = Vec_to_Mat(X, Subgroups=subgroups, Compartments=compartments)
mat_X_pos = mat_X[,grepl('_pos', colnames(mat_X))]
mat_X_gen = mat_X[,!grepl('_pos', colnames(mat_X))]
# Number of infections at time t for each subgroup
infec_gen = asymp_red*mat_X[,'Iasym'] + mat_X[,'Isym']
infec_pos = asymp_red*mat_X[,'Iasym_pos'] + mat_X[,'Isym_pos']
# Population sizes/testing status at time t
tot = rowSums(mat_X[,colnames(mat_X)!='D'])
tot_pos = rowSums(mat_X_pos)
tot_gen = rowSums(mat_X_gen[,colnames(mat_X_gen)!='D'])
#Fraction of population in each group who has tested positive by time
frac_released = tot_pos/tot
frac_distanced = c(rep(1,5))-frac_released
frac_comb = as.vector(rbind(frac_released, frac_distanced)) # interleaved
tot_pos[tot_pos==0] = tot[tot_pos==0] # avoid division by 0
# (1) Derive Contact Matrices ---------------------------------------------
# Home contacts
HighContact_Home = HomeContacts_5x5 %*% diag(frac_released)
LowContact_Home = HomeContacts_5x5 %*% diag(frac_distanced)
HomeContacts_10x10 = Expand_10x10(HighContact_Home, LowContact_Home)
# School contacts
HighContact_School = SchoolContacts_5x5 %*% diag(frac_released)
LowContact_School = SchoolContacts_5x5 %*% diag(frac_distanced)
SchoolContacts_10x10_Baseline = Expand_10x10(HighContact_School, LowContact_School)
SchoolContacts_10x10_reopen=Expand_10x10(SchoolContacts_5x5, 0, ZInflate=T)  #With general distancing, schools closed
# Work contacts
HighContact_Work = WorkContacts_5x5 %*% diag(frac_released)
LowContact_Work = WorkContacts_5x5 %*% diag(frac_distanced)
WorkContacts_10x10_Baseline = Expand_10x10(HighContact_Work, LowContact_Work) #Baseline matrix
# Broad distancing matrix
#   - Children have no work contacts
#   - Non-essential workers don't work
#   - Reduced contact workers reduce contacts by p_reduced and those contacts are
#     proportional to prevalence in the population
WorkContacts_10x10_Distancing = matrix(0, ncol=10, nrow=10)
WorkContacts_10x10_Distancing[5:6,] = WorkContacts_10x10_Baseline[5:6,]*p_reduced
WorkContacts_10x10_Distancing[7:8,] = WorkContacts_10x10_Baseline[7:8,]*p_full
# Targeted distancing work
#   - DISTANCING CONDITIONAL ON TESTING: People working from home regain their
#     workplace contacts if they test positive
#   - People in reduced and full contact occupations have the distribution of
#     their workplace contacts changed by alpha
#   - We use fixed shielding (except we multiply by alpha and not alpha +1),
#     so we correct for the situation where alpha times prevalence is greater than 1
Scale=frac_released*alpha
Scale[Scale>1]=1
WorkContacts_10x10_TargetedDistancing = matrix(0, nrow=10, ncol=10)
DistancedWork_RedContact = colSums(matrix(WorkContacts_10x10_Baseline[5,], nrow=2))
WorkContacts_10x10_TargetedDistancing[3,] = as.vector(rbind(WorkContacts_5x5[2,], rep(0,5)))
WorkContacts_10x10_TargetedDistancing[5,] = as.vector(rbind(Scale*DistancedWork_RedContact
, (1-Scale)*DistancedWork_RedContact))*p_reduced_c
WorkContacts_10x10_TargetedDistancing[6,]=WorkContacts_10x10_TargetedDistancing[5,]
WorkContacts_10x10_TargetedDistancing[7,]=WorkContacts_10x10_TargetedDistancing[5,]/p_reduced_c
WorkContacts_10x10_TargetedDistancing[8,]=WorkContacts_10x10_TargetedDistancing[5,]/p_reduced_c
# Other contacts
#   - BASELINE OTHER CONTACTS MATRIX: People mix freely, contacts are based
#     on proportion in the population
HighContact_Other = OtherContacts_5x5 %*% diag(frac_released)
LowContact_Other = OtherContacts_5x5 %*% diag(frac_distanced)
OtherContacts_10x10_Baseline = Expand_10x10(HighContact_Other, LowContact_Other)
#   - UNTARGETED SOCIAL DISTANCING OTHER CONTACTS: All contacts for social
#     distancing are reduced by a fraction
OtherContacts_10x10_Distancing = OtherContacts_10x10_Baseline*socialDistancing_other
#   - TARGETED SOCIAL DISTANCING OTHER CONTACTS: Shielding
#   - Contact probabilities proportional to prevalence in the population times
#     a scaling factor to account for shielding
#   - Keep the total contacts the same by subtracting from the total number
#     of expected contacts between age classes
#   - Once the scaling factor*prevalence exceeds 1, set to 1 (so that all
#     contacts are with a positive individual)
temp.other = Expand_10x10(OtherContacts_5x5, OtherContacts_5x5)
temp.other = t(t(temp.other)*as.vector(rbind(Scale, (1-Scale))))*socialDistancing_other_c
OtherContacts_10x10_TargetedDistancing = temp.other
#   - For test positive individuals, keep the distribution of other contacts
#     shielded but change the number to pre-pandemic levels
OtherContacts_10x10_TargetedDistancing_c=OtherContacts_10x10_TargetedDistancing
OtherContacts_10x10_TargetedDistancing_c[(1:5)*2-1,]=OtherContacts_10x10_TargetedDistancing[(1:5)*2-1,]/socialDistancing_other_c
# (2) Evolve Contact Matrices over time -----------------------------------
#Change matrices used over time
if(t<tStart_distancing | t>=tStart_reopen){ #Use baseline matrices until social distancing starts
CM = HomeContacts_10x10 +
SchoolContacts_10x10_Baseline +
WorkContacts_10x10_Baseline +
OtherContacts_10x10_Baseline
}
if(t>=tStart_distancing & t<tStart_reopen){
# if(t>=tStart_distancing & t<tStart_target){ #Use these matrices under general social distancing without testing
CM = HomeContacts_10x10 +
WorkContacts_10x10_Distancing +
OtherContacts_10x10_Distancing
}
if(t>=tStart_target & t<tStart_school){ #Use these matrices between the start of targeting and schools reopening
CM = HomeContacts_10x10 +
WorkContacts_10x10_TargetedDistancing +
OtherContacts_10x10_TargetedDistancing_c
}
if(t>=tStart_school){ #Keep most matrices the same but add schools back in
CM = HomeContacts_10x10 +
WorkContacts_10x10_TargetedDistancing +
OtherContacts_10x10_TargetedDistancing_c +
SchoolContacts_10x10_Baseline
}
# (3) Calculate v.fois ------------------------------------------------------
# Force of infection by group
temp.I = as.vector(rbind(infec_pos/tot_pos, infec_gen/tot_gen))
temp.I = t(t(CM)*temp.I)*q
v.fois = rowSums(temp.I)
names(v.fois) = c('foi_c_pos', 'foi_c_gen', 'foi_a_pos', 'foi_a_gen'
, 'foi_rc_pos', 'foi_rc_gen', 'foi_fc_pos', 'foi_fc_gen'
, 'foi_e_pos', 'foi_e_gen')
# Fois by pos or gen
v.fois_gen = v.fois[(1:5)*2]
v.fois_pos = v.fois[(1:5)*2-1]
# (4) Sero Testing --------------------------------------------------------
# Get number of tests available by group
v.avail_tests = daily_tests*agestruc[c(1,2,2,2,3)]*c(1,frac_home,frac_reduced,frac_full,1)
v.eligible_pop = rowSums(mat_X_gen[,c('S', 'E', 'Iasym', 'Hsub', 'Hcri', 'R')])
# Divide by number of test-eligible people for daily test fraction
v.daily_tests = v.avail_tests/v.eligible_pop
# When prevalence and testing are high, might not be enough eligible:
v.daily_tests[v.daily_tests>1] = 1
# (5) Model Equations -----------------------------------------------------
v.hosp_frac = hosp_frac[c(1,2,2,2,3)]
v.hosp_crit = hosp_crit[c(1,2,2,2,3)]
v.crit_die = crit_die[c(1,2,2,2,3)]
dS = -v.fois_gen*mat_X[,'S'] -
(1-specificity)*test.switch2*v.daily_tests*mat_X[,'S']
dE = v.fois_gen*mat_X[,'S'] -
gamma_e*mat_X[,'E'] -
(1-specificity)*test.switch2*v.daily_tests*mat_X[,'E']
dIsym = p_symptomatic*gamma_e*mat_X[,'E'] -
gamma_s*mat_X[,'Isym']
dIasym = (1-p_symptomatic)*gamma_e*mat_X[,'E'] -
gamma_a*mat_X[,'Iasym'] -
(1-specificity)*test.switch2*v.daily_tests*mat_X[,'Iasym']
dHsub = gamma_s*(v.hosp_frac-v.hosp_crit)*mat_X[,'Isym'] +
gamma_s*(v.hosp_frac-v.hosp_crit)*mat_X[,'Isym_pos'] -
gamma_hs*mat_X[,'Hsub']
dHcri = gamma_s*v.hosp_crit*mat_X[,'Isym'] +
gamma_s*v.hosp_crit*mat_X[,'Isym_pos'] -
gamma_hc*mat_X[,'Hcri']
dD = gamma_hc*v.crit_die*mat_X[,'Hcri']
dR = gamma_s*(1-v.hosp_frac)*mat_X[,'Isym'] +
gamma_a*mat_X[,'Iasym'] +
(1-sensitivity)*test.switch2*gamma_hs*mat_X[,'Hsub'] +
(1-sensitivity)*test.switch2*gamma_hc*(1-v.crit_die)*mat_X[,'Hcri'] -
sensitivity*test.switch2*v.daily_tests*mat_X[,'R'] +
gamma_hc*test.switch1*(1-v.crit_die)*mat_X[,'Hcri'] +
gamma_hs*test.switch1*mat_X[,'Hsub']
dS_pos = (1-specificity)*test.switch2*v.daily_tests*mat_X[,'S'] -
v.fois_pos*mat_X[,'S_pos']
dE_pos = (1-specificity)*test.switch2*v.daily_tests*mat_X[,'E'] +
v.fois_pos*mat_X[,'S_pos'] -
gamma_e*mat_X[,'E_pos']
dIsym_pos = p_symptomatic*gamma_e*mat_X[,'E_pos'] -
gamma_s*mat_X[,'Isym_pos']
dIasym_pos = (1-specificity)*test.switch2*v.daily_tests*mat_X[,'Iasym'] +
(1-p_symptomatic)*gamma_e*mat_X[,'E_pos'] -
gamma_a*mat_X[,'Iasym_pos']
dR_pos = sensitivity*test.switch2*v.daily_tests*mat_X[,'R'] +
sensitivity*test.switch2*gamma_hc*(1-v.crit_die)*mat_X[,'Hcri'] +
sensitivity*test.switch2*gamma_hs*mat_X[,'Hsub'] +
gamma_s*(1-v.hosp_frac)*mat_X[,'Isym_pos'] +
gamma_a*mat_X[,'Iasym_pos']
res = c(dS, dE, dIsym, dIasym, dHsub, dHcri, dD, dR, dS_pos, dE_pos, dIsym_pos, dIasym_pos, dR_pos)
names(res) = varNames
return(list(res))
}
